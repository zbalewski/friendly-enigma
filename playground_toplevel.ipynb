{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d02e44",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Let's-set-up-some-common-file-paths\" data-toc-modified-id=\"Let's-set-up-some-common-file-paths-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Let's set up some common file paths</a></span></li></ul></li><li><span><a href=\"#Behavior\" data-toc-modified-id=\"Behavior-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Behavior</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extract-sync-time-stamps\" data-toc-modified-id=\"Extract-sync-time-stamps-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Extract sync time stamps</a></span></li><li><span><a href=\"#Extract-some-trial-features-so-we-can-analyze-all-of-this-neural-data...\" data-toc-modified-id=\"Extract-some-trial-features-so-we-can-analyze-all-of-this-neural-data...-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Extract some trial features so we can analyze all of this neural data...</a></span></li></ul></li><li><span><a href=\"#Spikes\" data-toc-modified-id=\"Spikes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Spikes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Turn-spike-times-into-trains-and-firing-rates\" data-toc-modified-id=\"Turn-spike-times-into-trains-and-firing-rates-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Turn spike times into trains and firing rates</a></span></li><li><span><a href=\"#Chop-1-kHz-spike-data-into-trials-and-downsample,-aligned-to-event-timestamps-extracted-from-behavior\" data-toc-modified-id=\"Chop-1-kHz-spike-data-into-trials-and-downsample,-aligned-to-event-timestamps-extracted-from-behavior-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Chop 1 kHz spike data into trials and downsample, aligned to event timestamps extracted from behavior</a></span></li></ul></li><li><span><a href=\"#LFP\" data-toc-modified-id=\"LFP-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LFP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bandpass-and-smooth-LFP-in-standard-frequency-windows,-and-align-to-sync-points-(leave-at-1-kHz)\" data-toc-modified-id=\"Bandpass-and-smooth-LFP-in-standard-frequency-windows,-and-align-to-sync-points-(leave-at-1-kHz)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Bandpass and smooth LFP in standard frequency windows, and align to sync points (leave at 1 kHz)</a></span></li><li><span><a href=\"#Downsample-chopped-LFP\" data-toc-modified-id=\"Downsample-chopped-LFP-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Downsample chopped LFP</a></span></li></ul></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Let's-check-out-spikes-synced-to-the-start-of-the-trial\" data-toc-modified-id=\"Let's-check-out-spikes-synced-to-the-start-of-the-trial-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Let's check out spikes synced to the start of the trial</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb255e",
   "metadata": {},
   "source": [
    "Skeleton for final project..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c973300",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbacd18f",
   "metadata": {},
   "source": [
    "## Let's set up some common file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de7f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import h5py\n",
    "from os.path import join as pjoin\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.stats as stats\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8daecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data_clean\"\n",
    "session = \"George00_rec14_01282021\"\n",
    "\n",
    "bhv_fnames = sorted(glob.glob(pjoin(data_dir, session + \"*bhv*\"))) # could be >1\n",
    "spk_fname = glob.glob(pjoin(data_dir, session + \"*units*\"))[0] # expect 1\n",
    "lfp_fname = glob.glob(pjoin(data_dir, session + \"*LFP*\"))[0] # expect 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729c048",
   "metadata": {},
   "source": [
    "# Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377568be",
   "metadata": {},
   "source": [
    "## Extract sync time stamps\n",
    "\n",
    "For each session, we want to pull out snippets around task events. Two standard sync points are the start (pictures are displayed on the screen) and end (animal makes a selection with a lever movement) of each trial. This function could be customized easily-- we just need a vector of time stamps (in seconds) to align the neural data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296982c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_bhv(bhv_fnames):\n",
    "    \"\"\"\n",
    "    Load raw bhv (.bhv2 saved as .mat) into dict; consolidate \n",
    "    if split across multiple files (assume alpha order)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    bhv_fnames : list \n",
    "        File path(s) for behavior data\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    bhv_data : dict\n",
    "        All task data\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    bhv_data = defaultdict(list)\n",
    "    \n",
    "    for f in bhv_fnames:\n",
    "        print(f)\n",
    "        data = mat73.loadmat(f)\n",
    "\n",
    "        data_vars = data[\"bhvdata\"].keys()\n",
    "        for v in data_vars:\n",
    "            bhv_data[v] += data[\"bhvdata\"][v]\n",
    "            \n",
    "    return bhv_data\n",
    "\n",
    "def load_pl2_codes(spk_fname):\n",
    "    \"\"\"\n",
    "    Load task event codes and corresponding time stamps from \n",
    "    raw spk (.pl2 saved as .mat).\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    spk_fname : string\n",
    "        File path for spk data\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    pl2_codes : dict\n",
    "        Event codes and timestamps from whole session\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pl2_codes = mat73.loadmat(spk_fname, \\\n",
    "                              only_include=[\"event_codes\", \"event_ts\"])\n",
    "    \n",
    "    return pl2_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965f6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_events(bhv_data, pl2_codes, event):\n",
    "    \"\"\"\n",
    "    For each trial in bhv_data, pull time for this event code \n",
    "    (-1 if doesn't exist)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    bhv_data : dict\n",
    "        All task data\n",
    "    pl2_codes : dict\n",
    "        Event codes and timestamps from whole session\n",
    "    event : int\n",
    "        Event code word\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    timestamps : np vector\n",
    "        Timestamps corresponding to event within each trial (or -1)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # cut up trials by default start and stop codes\n",
    "    start_code = 9\n",
    "    stop_code = 18\n",
    "    \n",
    "    trial_start = np.where(pl2_codes[\"event_codes\"] == start_code)[0]\n",
    "    trial_stop = np.where(pl2_codes[\"event_codes\"] == stop_code)[0]\n",
    "    \n",
    "    # check that we have the same number of trials from bhv and pl2 data\n",
    "    ntr = len(bhv_data[\"Trial\"])\n",
    "    if trial_start.shape[0] != ntr or trial_stop.shape[0] != ntr:\n",
    "        raise ValueError(\"oops! mismatched bhv2 and pl2 trial counts\")\n",
    "    \n",
    "    # cycle through all trials, save event time (if exists)\n",
    "    timestamps = -1 * np.ones(ntr)\n",
    "    for tr in range(ntr):\n",
    "        \n",
    "        # restrict to event codes in this trial\n",
    "        codes = pl2_codes[\"event_codes\"][trial_start[tr] : trial_stop[tr]]\n",
    "        ts = pl2_codes[\"event_ts\"][trial_start[tr] : trial_stop[tr]]\n",
    "        \n",
    "        idx = np.where(codes == event)[0]\n",
    "        if idx.shape[0] == 1:\n",
    "            timestamps[tr] = ts[idx]\n",
    "    \n",
    "    return timestamps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cde6d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_clean/George00_rec14_01282021-bhv_A.mat\n",
      "data_clean/George00_rec14_01282021-bhv_B.mat\n",
      "data_clean/George00_rec14_01282021-bhv_C.mat\n"
     ]
    }
   ],
   "source": [
    "# load bhv data for this session\n",
    "bhv_data = load_raw_bhv(bhv_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964f1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spk events for this session\n",
    "pl2_codes = load_pl2_codes(spk_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb8d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([863.,  77.,  70.,  70.,  75.,  67.,  52.,  51.,  49.,  43.]),\n",
       " array([-1.00000000e+00,  7.05580460e+02,  1.41216092e+03,  2.11874138e+03,\n",
       "         2.82532184e+03,  3.53190230e+03,  4.23848276e+03,  4.94506322e+03,\n",
       "         5.65164368e+03,  6.35822414e+03,  7.06480460e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get time stamps for pictures and lever responses\n",
    "ts_pics = get_trial_events(bhv_data, pl2_codes, 20)\n",
    "ts_left = get_trial_events(bhv_data, pl2_codes, 23)\n",
    "ts_right = get_trial_events(bhv_data, pl2_codes, 24)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.hist(ts_pics)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.hist(ts_left)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.hist(ts_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f12fee",
   "metadata": {},
   "source": [
    "## Extract some trial features so we can analyze all of this neural data..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca045c6",
   "metadata": {},
   "source": [
    "# Spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e77145",
   "metadata": {},
   "source": [
    "## Turn spike times into trains and firing rates\n",
    "\n",
    "The raw data contains spike times at 40 kHz for each neuron. While this is an efficient way to store data, it's often more convenient to visualize/to analyses on spike trains (e.g. 0 0 1 1 0 0 1 0) or smoothed firing rates (trains with 50ms boxcar smoothing) at 1 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096ad6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_spk(spk_fname):\n",
    "    \"\"\"\n",
    "    Load raw spk (.pl2 saved as .mat)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    spk_fname : string\n",
    "        Path file for raw spk data\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    raster : np array\n",
    "        spike trains, nunits x ntimes \n",
    "    fr : np array\n",
    "        firing rates, nunits x ntimes\n",
    "    unit_meta : pd table\n",
    "        meta data; each row corresponds to row in raster and fr\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # load spk data\n",
    "    data = mat73.loadmat(spk_fname)\n",
    "\n",
    "    # get unique unit names\n",
    "    unit_names = [u[0] for u in data[\"unit_names\"]]\n",
    "    nunits = len(unit_names)\n",
    "    \n",
    "    # get last spike time in entire session, +1 second\n",
    "    last_spk = [data[u][-1] for u in unit_names]\n",
    "    max_t = 1 + max(last_spk) \n",
    "    ts = np.arange(np.round(1000 * max_t)) # ms, corresponding time vector \n",
    "    ntimes = len(ts)\n",
    "    \n",
    "    # get spike trains for all units\n",
    "    raster = get_raster(data, unit_names, ntimes)\n",
    "    \n",
    "    # smooth spike trains into firig rates\n",
    "    fr = get_fr(raster)\n",
    "     \n",
    "    # save some meta data for each unit\n",
    "    mean_fr = [len(data[u])/max_t for u in unit_names]\n",
    "    channel = [int(u.replace(\"SPK_SPKC\",\"\")[:3]) for u in unit_names]\n",
    "    unit_meta = pd.DataFrame({\"ID\" : unit_names,\n",
    "                              \"channel\" : channel,\n",
    "                              \"mean_fr\" : mean_fr})\n",
    "    \n",
    "    return raster, fr, unit_meta\n",
    "    \n",
    "def get_raster(data, unit_names, ntimes):\n",
    "    \"\"\"\n",
    "    Turn spike times into trains, for all units in data.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : dict\n",
    "        spk data, with unit spike times plus some meta data\n",
    "    unit_names : list of strings\n",
    "        unit names\n",
    "    ntimes : int\n",
    "        index of max time point\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    raster : 2D np array\n",
    "        units x time, spikes @ 1 kHz\n",
    "        \n",
    "    \"\"\"\n",
    "    nunits = len(unit_names)\n",
    "    raster = np.empty((nunits, ntimes))\n",
    "    for u in range(nunits):\n",
    "        raster[u, :] = ts_to_train(data[unit_names[u]], ntimes)\n",
    "        \n",
    "    return raster\n",
    "\n",
    "\n",
    "def get_fr(raster):\n",
    "    \"\"\"\n",
    "    Turn raster (for units x entire session) into firing rates.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    raster : 2D np array\n",
    "        units x time, spikes @ 1 kHz\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    fr : 2D np array\n",
    "        units x time, firing rates @ 1kHz (per ms; *1000 to get Hz)\n",
    "    \n",
    "    \"\"\"\n",
    "    fr = np.empty(raster.shape)\n",
    "    for u in range(raster.shape[0]):\n",
    "        fr[u, :] = train_to_fr(raster[u, :])\n",
    "    \n",
    "    return fr\n",
    "\n",
    "\n",
    "def ts_to_train(timestamps, ntimes):\n",
    "    \"\"\"\n",
    "    Turn spike timestamps into a spike train.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    timestamps : np vector\n",
    "        Times this unit fired, in sec\n",
    "    ntimes : int\n",
    "        Max time index\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    train : np vector\n",
    "        1 or 0 to indicate spike in that time window\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    # make train of same size\n",
    "    train = np.zeros((1, ntimes))\n",
    "    \n",
    "    # set train = 1 at closest time stamp\n",
    "    timestamps_ms = np.round(1000 * timestamps).astype(int)\n",
    "    train[:, timestamps_ms] = 1\n",
    "    \n",
    "    return train\n",
    "\n",
    "\n",
    "def train_to_fr(train):\n",
    "    \"\"\"\n",
    "    Turn spike train into firing rate. \n",
    "    Note: can also use this to smooth LFP magnitude!\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    train : np vector\n",
    "        1 or 0 to indicate spike in that time window\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    train_smoothed : np vector\n",
    "        train with 50 ms boxcar smoothing\n",
    "        \n",
    "    \"\"\"\n",
    "    # define boxcar smooth\n",
    "    box = signal.boxcar(49) / 49\n",
    "    \n",
    "    # apply smoothing\n",
    "    train_smoothed = np.convolve(train, box, \"same\")\n",
    "    \n",
    "    return train_smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca65ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 s, sys: 10.1 s, total: 40.2 s\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raster, fr, unit_meta = process_raw_spk(spk_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d22c2d",
   "metadata": {},
   "source": [
    "## Chop 1 kHz spike data into trials and downsample, aligned to event timestamps extracted from behavior\n",
    "\n",
    "Using the time stamps pulled from the behavior, we can look at the same time period across all trials synced to specific events (e.g. start or end of trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd1b1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chop up long neural data into trials\n",
    "def chop(long_brain, sync_points, window):\n",
    "    \"\"\"\n",
    "    Chop up 2 hr session into snippets around sync points.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    long_brain : 2D np array\n",
    "        units x time (e.g. spike train, LFP magnitude)\n",
    "    sync_points : np vector\n",
    "        sync points across session, e.g. start time for all trials\n",
    "    window : tuple (2 element)\n",
    "        time window around sync point (in seconds)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    chopped_brain : 3D np array\n",
    "        sync_points x time x units\n",
    "        \n",
    "    \"\"\"\n",
    "    # number of units\n",
    "    nunits = long_brain.shape[0]\n",
    "    \n",
    "    # time window index\n",
    "    t_idx = np.arange(window[0] * 1000, window[1] * 1000) # use ms!\n",
    "    nt = t_idx.shape[0]\n",
    "    \n",
    "    # sync point index\n",
    "    sync_idx = np.round(sync_points * 1000) # use ms!\n",
    "    sync_idx[sync_idx == -1000] = -1 # manual fix; these trials are missing events\n",
    "    nsync = sync_idx.shape[0]\n",
    "    \n",
    "    # make index matrix\n",
    "    tile_time = np.tile(t_idx.reshape(1, -1), (nsync, 1))\n",
    "    tile_sync = np.tile(sync_idx.reshape(-1, 1), (1, nt))\n",
    "    \n",
    "    long_idx = (tile_time + tile_sync).astype(int)\n",
    "    long_idx[tile_sync == -1] = -1 # same manual fix\n",
    "    \n",
    "    # chop up each unit...\n",
    "    chopped_brain = np.empty((nsync, nt, nunits))\n",
    "    for u in range(nunits):\n",
    "        chopped_brain[:, :, u] = long_brain[u, :][long_idx]\n",
    "    \n",
    "    if nunits == 1:\n",
    "        chopped_brain = np.squeeze(chopped_brain)\n",
    "        \n",
    "    return chopped_brain\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "822c9b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 6.11 s, total: 17.4 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_chopped = chop(raster, ts_pics, (-1, 1))\n",
    "fr_chopped = chop(fr, ts_pics, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db31f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth chooped neural data\n",
    "def sliding_avg(data, ts, time_range, window, step=0.25):\n",
    "    \"\"\"\n",
    "    Downsample by averaging in window offset by step (window fraction) \n",
    "    along axis=1 (time). Assume data @ 1 kHz, and window given in \n",
    "    seconds; step is fraction of window. \n",
    "    \n",
    "    TODO: make this more flexible for other units; will still run right \n",
    "    now but results could be incorrect...\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : 3D np array\n",
    "        sync points x time x units, sampled at 1 kHz\n",
    "    ts : np vector\n",
    "        timestamps corresponding to time axis in data, assume seconds\n",
    "    time_range : tuple\n",
    "        restricted time range from full ts\n",
    "    window : float\n",
    "        size of averging window\n",
    "    step : float\n",
    "        offset between averaging windows, given by fraction of \n",
    "        window; must be >0, and 1 = no overlap. \n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # check that step makes sense...\n",
    "    if step <= 0 or step > 1:\n",
    "        raise ValueError(\"Bad choice for sliding window average! \" +\\\n",
    "                         \"step' is fraction of window, must be > 0 and <= 1\")\n",
    "\n",
    "    # check that time range makes sense...\n",
    "    if time_range[0] >= time_range[1]:\n",
    "        raise ValueError(\"Bad choice for sliding window average! \" +\\\n",
    "                        \"'time_range' is not sensible\")\n",
    "    adjusted_time_range = np.array([\n",
    "        np.max([time_range[0], ts[0]]), \n",
    "        np.min([time_range[1], ts[-1]])])\n",
    "    \n",
    "    # get size of data\n",
    "    nsync, ntimes, nunits = data.shape\n",
    "    \n",
    "    # set window and offset sizes, in ms\n",
    "    window_ms = np.round(1000 * window)\n",
    "    offset_ms = np.round(window_ms * step)\n",
    "    \n",
    "    # find midpoints for averaging windows\n",
    "    start_idx = np.floor(np.argmin(np.abs(ts - adjusted_time_range[0])) + window_ms/2)\n",
    "    stop_idx = np.ceil(1 + np.argmin(np.abs(ts - adjusted_time_range[1])) - window_ms/2)\n",
    "    mid_idx = np.arange(start_idx, stop_idx, offset_ms).astype(int)\n",
    "    mid_times = ts[mid_idx]\n",
    "    \n",
    "    # do sliding averages\n",
    "    data_smooth = np.empty((nsync, len(mid_idx), nunits))\n",
    "    t_idx = np.arange(-np.floor(window_ms / 2), np.ceil(window_ms / 2)).astype(int)\n",
    "    \n",
    "    for i in range(len(mid_idx)):\n",
    "        data_smooth[:, i, :] = data[:, mid_idx[i] + t_idx, :].mean(axis=1)\n",
    "    \n",
    "    \n",
    "    return mid_times, data_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e5ea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 3.4 s, total: 8.05 s\n",
      "Wall time: 8.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# smooth firing rates with 500ms sliding windows, from -2 to 2 sec around sync point\n",
    "ts = np.arange(-1, 1, 0.001)\n",
    "mid_times_500ms, data_smooth_500ms = sliding_avg(fr_chopped, ts, (-1, 1), 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "776c7c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.35 s, sys: 3.89 s, total: 9.24 s\n",
      "Wall time: 9.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# smooth firing rates with 200ms sliding windows, from -1 to 1 sec around sync point\n",
    "mid_times_200ms, data_smooth_200ms = sliding_avg(fr_chopped, ts, (-1, 1), 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630c406",
   "metadata": {},
   "source": [
    "# LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f357068",
   "metadata": {},
   "source": [
    "## Bandpass and smooth LFP in standard frequency windows, and align to sync points (leave at 1 kHz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6966430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_raw_lfp(lfp_fname, sync_point, time_range):\n",
    "    \"\"\"\n",
    "    Load raw lfp (.pl2 saved as .mat)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    lfp_fname : string\n",
    "        Path file for raw lfp data\n",
    "    sync_point : np vector\n",
    "        Times to sync across session (e.g. trial start)\n",
    "    time_range : 2 element tuple\n",
    "        Time range around sync points, in sec\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    band_mag_chopped_np : list\n",
    "        of 3D np arrays with each bandpass magnitude; sync_points x time x channels\n",
    "    band_phs_chopped_np : list\n",
    "        of 3D np arrays with each bandpass phase; sync_points x time x channels\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # get channel names\n",
    "    f = h5py.File(lfp_fname, \"r\")\n",
    "    channel_names = [key for key in f.keys() if key.find(\"FP\") == 0]\n",
    "    \n",
    "    # get lfp time \n",
    "    data = mat73.loadmat(lfp_fname, only_include=\"lfp_ts\")\n",
    "    ts_long = data[\"lfp_ts\"]/1000 # time in seconds\n",
    "    \n",
    "    # make notch filters\n",
    "    notch_hz = [60, 120, 180] # Hz\n",
    "    notch_filts = [signal.iirnotch(n, n, 1000) for n in notch_hz]\n",
    "    \n",
    "    # make bandpass filters\n",
    "    band_hz = [[2, 4], [4, 8], [8, 12], [12, 30], [30, 60], [70, 200]] # Hz\n",
    "    band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\", \"high gamma\"]\n",
    "    band_filts = [signal.firwin(1000, [b[0], b[1]], pass_zero=False, \n",
    "                                fs=1000) for b in band_hz]\n",
    "    \n",
    "    # get chopped time index\n",
    "    ts_chopped = np.arange(-2, 2, 0.001) \n",
    "    \n",
    "    # init dicts to keep track of all channels     \n",
    "    band_mag_chopped = dict()\n",
    "    band_phs_chopped = dict()\n",
    "    for b in band_names:\n",
    "        band_mag_chopped[b] = [None] * len(channel_names)\n",
    "        band_phs_chopped[b] = [None] * len(channel_names)\n",
    "    \n",
    "    # get bandpassed signal and chop into trials \n",
    "    for ch in range(len(channel_names)): # TODO: PARALLELIZE!\n",
    "        print('working on band pass...' + channel_names[ch])\n",
    "        # load, notch, and bandpass this channel\n",
    "        mag, phs = get_bandpassed(channel_names[ch], lfp_fname,\n",
    "                                        ts, notch_filts, band_filts)\n",
    "        # chop by sync points\n",
    "        mag_chopped = [chop(m.reshape(1, -1), sync_point, time_range) \n",
    "                       for m in mag]\n",
    "        phs_chopped = [chop(p.reshape(1, -1), sync_point, time_range) \n",
    "                       for p in phs]\n",
    "        \n",
    "        # slot in results\n",
    "        for b in range(len(band_names)):\n",
    "            band_mag_chopped[band_names[b]][ch] = mag_chopped[b]\n",
    "            band_phs_chopped[band_names[b]][ch] = phs_chopped[b]\n",
    "        \n",
    "    # cat all channels together for 3D array: sync_points x time x channels\n",
    "    band_mag_chopped_np = [np.stack(band_mag_chopped[b], axis=2) for b in band_names]\n",
    "    band_phs_chopped_np = [np.stack(band_phs_chopped[b], axis=2) for b in band_names]\n",
    "    \n",
    "    return band_mag_chopped_np, band_phs_chopped_np\n",
    "\n",
    "\n",
    "def get_bandpassed(chname, fname, ts, notch_filts, band_filts):\n",
    "    \"\"\"\n",
    "    Get mag and phase for bandpassed LFP channel.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    chname : string\n",
    "        channel ID\n",
    "    lfp_name : string\n",
    "        path to LFP data\n",
    "    ts : np vector\n",
    "        time stamps for LFP timeseries (in seconds)\n",
    "    notch_filts : list\n",
    "        notch filters\n",
    "    band_filts : list\n",
    "        bandpass filters\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    mag : list\n",
    "        np vectors with magntiude of signal in each band_filts\n",
    "    phs : list\n",
    "        np vectors with phase of signal in each band_filt\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # load lfp channel\n",
    "    data = mat73.loadmat(fname, only_include=chname)\n",
    "    channel = data[chname]\n",
    "    \n",
    "    # apply notch filters serially\n",
    "    for notch in notch_filts:\n",
    "        channel = signal.filtfilt(notch[0], notch[1], channel)\n",
    "    \n",
    "    # apply each band pass separately\n",
    "    bandpassed = [signal.filtfilt(band, 1, channel) \n",
    "                  for band in band_filts]\n",
    "    \n",
    "    # get analytic signal\n",
    "    analytic = [signal.hilbert(b) for b in bandpassed]\n",
    "    \n",
    "    # get magnitude, smooth with 50ms boxcar\n",
    "    mag_raw = [train_to_fr(np.abs(a)) for a in analytic]\n",
    "    mag = [stats.zscore(m) for m in mag_raw]\n",
    "    \n",
    "    # get phase\n",
    "    phs = [np.angle(a) for a in analytic]\n",
    "    \n",
    "    return mag, phs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea1d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on band pass...FP065\n",
      "working on band pass...FP066\n",
      "working on band pass...FP067\n",
      "working on band pass...FP068\n",
      "working on band pass...FP069\n",
      "working on band pass...FP070\n",
      "working on band pass...FP071\n",
      "working on band pass...FP072\n",
      "working on band pass...FP073\n",
      "working on band pass...FP074\n",
      "working on band pass...FP075\n",
      "working on band pass...FP076\n",
      "working on band pass...FP077\n",
      "working on band pass...FP078\n",
      "working on band pass...FP079\n",
      "working on band pass...FP080\n",
      "working on band pass...FP081\n",
      "working on band pass...FP082\n",
      "working on band pass...FP083\n",
      "working on band pass...FP084\n",
      "working on band pass...FP085\n",
      "working on band pass...FP086\n",
      "working on band pass...FP087\n",
      "working on band pass...FP088\n",
      "working on band pass...FP089\n",
      "working on band pass...FP090\n",
      "working on band pass...FP091\n",
      "working on band pass...FP092\n",
      "working on band pass...FP093\n",
      "working on band pass...FP094\n",
      "working on band pass...FP095\n",
      "working on band pass...FP096\n",
      "working on band pass...FP097\n",
      "working on band pass...FP098\n",
      "working on band pass...FP099\n",
      "working on band pass...FP100\n",
      "working on band pass...FP101\n",
      "working on band pass...FP102\n",
      "working on band pass...FP103\n",
      "working on band pass...FP104\n",
      "working on band pass...FP105\n",
      "working on band pass...FP106\n",
      "working on band pass...FP107\n",
      "working on band pass...FP108\n",
      "working on band pass...FP109\n",
      "working on band pass...FP110\n",
      "working on band pass...FP111\n",
      "working on band pass...FP112\n",
      "working on band pass...FP113\n",
      "working on band pass...FP114\n",
      "working on band pass...FP115\n",
      "working on band pass...FP116\n",
      "working on band pass...FP117\n",
      "working on band pass...FP118\n",
      "working on band pass...FP119\n",
      "working on band pass...FP120\n",
      "working on band pass...FP121\n",
      "working on band pass...FP122\n",
      "working on band pass...FP123\n",
      "working on band pass...FP124\n",
      "working on band pass...FP125\n",
      "working on band pass...FP126\n",
      "working on band pass...FP127\n",
      "working on band pass...FP128\n",
      "working on band pass...FP193\n",
      "working on band pass...FP194\n",
      "working on band pass...FP195\n",
      "working on band pass...FP196\n",
      "working on band pass...FP197\n",
      "working on band pass...FP198\n",
      "working on band pass...FP199\n",
      "working on band pass...FP200\n",
      "working on band pass...FP201\n",
      "working on band pass...FP202\n",
      "working on band pass...FP203\n",
      "working on band pass...FP204\n",
      "working on band pass...FP205\n",
      "working on band pass...FP206\n",
      "working on band pass...FP207\n",
      "working on band pass...FP208\n",
      "working on band pass...FP209\n",
      "working on band pass...FP210\n",
      "working on band pass...FP211\n",
      "working on band pass...FP212\n",
      "working on band pass...FP213\n",
      "working on band pass...FP214\n",
      "working on band pass...FP215\n",
      "working on band pass...FP216\n",
      "working on band pass...FP217\n",
      "working on band pass...FP218\n",
      "working on band pass...FP219\n",
      "working on band pass...FP220\n",
      "working on band pass...FP221\n",
      "working on band pass...FP222\n",
      "working on band pass...FP223\n",
      "working on band pass...FP224\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mag_chopped, phs_chopped = process_raw_lfp(lfp_fname,  ts_pics, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54921b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(band_phs_chopped_np[3][:, :, 0], cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94d0cc",
   "metadata": {},
   "source": [
    "## Downsample chopped LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f23c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# smooth firing rates with 500ms sliding windows, from -2 to 2 sec around sync point\n",
    "ts = np.arange(-2, 2, 0.001)\n",
    "mid_times_500ms, theta_smooth_500ms = sliding_avg(mag[1], ts, (-1, 1), 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ddb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# smooth firing rates with 200ms sliding windows, from -1 to 1 sec around sync point\n",
    "mid_times_200ms, theta_smooth_200ms = sliding_avg(mag[0], ts, (-1, 1), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d8a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4bfe776",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b382611",
   "metadata": {},
   "source": [
    "## Let's check out spikes synced to the start of the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d76864",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_units = [40, 43, 53, 96, 69]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "t_idx = np.arange(-2000, 2000)\n",
    "\n",
    "for u in range(len(fun_units)):\n",
    "    ax = fig.add_subplot(5, 1, u + 1)\n",
    "    ax.plot(t_idx, 1000*np.mean(fr_chopped[:, :, fun_units[u]], axis=0))\n",
    "    \n",
    "    y = ax.get_ylim()\n",
    "    new_y = (0, y[1])\n",
    "    \n",
    "    ax.plot(np.array([0, 0]), new_y, \"k\")\n",
    "    ax.plot(np.array([-750, -750]), new_y, \"k:\")\n",
    "\n",
    "ax.set_xlabel(\"Time from sync (ms)\")\n",
    "ax.set_ylabel(\"Firing rate (Hz)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aba531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
